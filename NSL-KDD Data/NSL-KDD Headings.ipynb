{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816910df-f00a-4433-a643-e6e134e2e667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 125973 rows.\n",
      "Read 22544 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6g/p3q58mdj0cz5m1zbkcgdzbsm0000gn/T/ipykernel_51445/2028858521.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_train_df = pd.concat([final_train_df, label_train_df])\n",
      "/var/folders/6g/p3q58mdj0cz5m1zbkcgdzbsm0000gn/T/ipykernel_51445/2028858521.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_test_df = pd.concat([final_test_df, label_test_df])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set distribution:\n",
      "outcome\n",
      "normal     0.534583\n",
      "neptune    0.327165\n",
      "             ...   \n",
      "perl       0.000024\n",
      "spy        0.000016\n",
      "Name: proportion, Length: 23, dtype: float64\n",
      "\n",
      "Test set distribution:\n",
      "outcome\n",
      "normal     0.430758\n",
      "neptune    0.206574\n",
      "             ...   \n",
      "phf        0.000089\n",
      "imap       0.000044\n",
      "Name: proportion, Length: 38, dtype: float64\n",
      "New training set:\n",
      "   duration protocol_type   service  ... dst_host_srv_rerror_rate outcome  \\\n",
      "0         0           tcp  ftp_data  ...                     0.00  normal   \n",
      "1         0           udp     other  ...                     0.00  normal   \n",
      "3         0           tcp      http  ...                     0.01  normal   \n",
      "4         0           tcp      http  ...                     0.00  normal   \n",
      "12        0           tcp      http  ...                     0.00  normal   \n",
      "\n",
      "   difficulty_level  \n",
      "0                20  \n",
      "1                15  \n",
      "3                21  \n",
      "4                21  \n",
      "12               21  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "\n",
      "New test set:\n",
      "   duration protocol_type  service  ... dst_host_srv_rerror_rate  outcome  \\\n",
      "0         0           tcp  private  ...                      1.0  neptune   \n",
      "1         0           tcp  private  ...                      1.0  neptune   \n",
      "12        0           tcp  private  ...                      1.0  neptune   \n",
      "13        0           tcp   telnet  ...                      0.0  neptune   \n",
      "19        0           tcp  private  ...                      1.0  neptune   \n",
      "\n",
      "   difficulty_level  \n",
      "0                21  \n",
      "1                21  \n",
      "12               21  \n",
      "13               18  \n",
      "19               21  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 6)\n",
    "pd.set_option('display.max_rows', 5)\n",
    "\n",
    "train_path = 'KDDTrain+.csv'\n",
    "test_path = 'KDDTest+.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path, header=None)\n",
    "test_df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "\n",
    "print(\"Read {} rows.\".format(len(train_df)))\n",
    "print(\"Read {} rows.\".format(len(test_df)))\n",
    "\n",
    "train_df.dropna(inplace=True, axis=1)\n",
    "test_df.dropna(inplace=True, axis=1)\n",
    "\n",
    "\n",
    "#label names are courtesy of a KDDCup Data file analysis video\n",
    "train_df.columns = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
    "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
    "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login',\n",
    "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
    "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'outcome', 'difficulty_level'\n",
    "]\n",
    "\n",
    "test_df.columns = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
    "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
    "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login',\n",
    "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
    "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'outcome', 'difficulty_level'\n",
    "]\n",
    "\n",
    "train_unique_labels = train_df['outcome'].unique()\n",
    "test_unique_labels = test_df['outcome'].unique()\n",
    "\n",
    "\n",
    "final_train_df = pd.DataFrame(columns=train_df.columns)\n",
    "final_test_df = pd.DataFrame(columns=test_df.columns)\n",
    "\n",
    "for label in train_unique_labels:\n",
    "    label_train_df = train_df[train_df['outcome'] == label]\n",
    "    final_train_df = pd.concat([final_train_df, label_train_df])\n",
    "\n",
    "for label in test_unique_labels:\n",
    "    label_test_df = test_df[test_df['outcome'] == label]\n",
    "    final_test_df = pd.concat([final_test_df, label_test_df])\n",
    "\n",
    "train_labels = final_train_df['outcome']\n",
    "test_labels = final_test_df['outcome']\n",
    "\n",
    "print('Training set distribution:')\n",
    "print(train_labels.value_counts(normalize=True))\n",
    "print('\\nTest set distribution:')\n",
    "print(test_labels.value_counts(normalize=True))\n",
    "\n",
    "#outputs the training and testing files with headings. The files have not formally been split to make sure each label is represented, though.\n",
    "final_train_df.to_csv('train_detailed.csv', index=False)\n",
    "final_test_df.to_csv('test_detailed.csv', index=False)\n",
    "\n",
    "print(\"New training set:\")\n",
    "print(final_train_df.head())\n",
    "print(\"\\nNew test set:\")\n",
    "print(final_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64073950-dfab-4cb1-812c-ae1b713c1120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
